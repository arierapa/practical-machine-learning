**Practical Machine Learning - Prediction Assignment Write-up**

**Background**

Using devices such as _Jawbone Up_, _Nike FuelBand_, and _Fitbit_ it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how _much_ of a particular activity they do, but they rarely quantify _how well they do it_.

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here:  [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).

**Data**

The training data for this project are available here:
 [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)

The test data are available here:
 [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

The data for this project come from this source:  [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har). If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.

**Goal**

The goal of the project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

**Development**

1.- I first loaded the data into the training and testing set. We defined the NA in order to check where there is no information.

training<-read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!",""))

testing<-read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!",""))

2.- I did some exploratory analysis and cleaning

dim(training)

[1] 19622   160

dim(testing)

[1]  20 160

There are 19,622 instances for training with 160 variables, 20 instances for testing.

I realized that there are many NAs in some variables. The idea is to find the variables that have more than 10,000 NAs and take them out of the data sets (50% of the data).

finding the variables (columns) that have more than 10,000 NA

nac<-colSums(is.na(training))>10000

sum(nac)

[1] 100

There are 100 variables where there are more than 10,000 NA .

I removed the columns (variable) that have more than 10,000 NA

training2<-training[,-which(nac==TRUE)]

I removed first row that do not have information for predictions

training3<-training2[,-1]

3.- Fitting a Model

library(caret)

set.seed(32243)

I created the data partitioning

inTrain<-createDataPartition(training3$classe,p=0.6,list=FALSE)

train <- training3[inTrain,]

test<- training3[-inTrain,]

CART

The first model I used is CART model from Caret package.

modelFitRP<-train(classe~.,data=train,method="rpart")

ModelFitRP

Accuracy = 0.61

The accuracy in this model in the training set is 0.61. I will check in the testing set.

predRP<-predict(modelFitRP,newdata=test)

confusionMatrix(predRP,test$classe)

Accuracy = 0.63

The accuracy in this model in the testing set is 0.63. It seems there is no overfitting.

CART WITH RPART

I will use now CART model from Rpart package.

library(rpart)

modelFitRP2<- rpart(classe ~ ., data=train, method="class")

predRP2<-predict(modelFitRP2,test,type="class")

confusionMatrix(predRP2,test$classe)

Accuracy = 0.87

The accuracy in this model in the testing set is 0.87.

RANDOM FOREST

I will use now Random Forest model from randomForest package.

library(randomForest)

modelFitRF <- randomForest(classe ~. , data=train)

predRF<-predict(modelFitRF,test,type="class")

confusionMatrix(predRF,test$classe)

Accuracy = 0.99

The accuracy in this model in the testing set is 0.99.

**Conclusions**

If we compare CART model and Random Forest, the first one provide accuracy of 0.87 and the second one 0.99. We choose Random Forest as the model to evaluate the testing data set.

predicting on the testing data set of 20 instances

testing2<-testing[,-which(nac==TRUE)]

testing3<-testing2[,-1]

I had to use the same levels from the training set

levels(testing3$cvtd\_timestamp) = levels(train$cvtd\_timestamp)

levels(testing3$new\_window) = levels(train$new\_window)

predRPt<-predict(modelFitRF,testing3,type="class")

answers = as.character(predRPt)

answers

These are the predictions for the 20 test cases.

[1] "B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B"

[20] "B"

I will now created the 20 files for the Course Project Submission:

pml\_write\_files = function(x){

  n = length(x)

  for(i in 1:n){

    filename = paste0("problem\_id\_",i,".txt")

    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)

  }

}

pml\_write\_files(answers)
